Instructions
List the names of the Top 5 products by revenue ordered on '2013-07-26'. Revenue is considered only for COMPLETE and CLOSED orders.

Data Description
retail_db data is available in HDFS at /public/retail_db

retail_db data information:

Source directories:
/public/retail_db/orders
/public/retail_db/order_items
/public/retail_db/products
Source delimiter: comma(",")
Source Columns - orders - order_id, order_date, order_customer_id, order_status
Source Columns - order_itemss - order_item_id, order_item_order_id, order_item_product_id, order_item_quantity, order_item_subtotal, order_item_product_price
Source Columns - products - product_id, product_category_id, product_name, product_description, product_price, product_image
Output Requirements
Target Columns: order_date, order_revenue, product_name, product_category_id
Data has to be sorted in descending order by order_revenue
File Format: text
Delimiter: colon (:)
Place the output file in the HDFS directory
/user/`whoami`/problem7/solution/
Replace `whoami` with your OS user name
End of Problem

val p7ord = spark.read.option("inferSchema","true").csv("/public/retail_db/orders").toDF("order_id", "order_date", "order_customer_id", "order_status").filter("order_date ='2013-07-26' and order_status in ('COMPLETE','CLOSED')")val p7oitm =spark.read.option("inferSchema","true").csv("/public/retail_db/order_items").toDF("order_item_id","order_item_order_id","order_item_product_id","order_item_quantity","order_item_subtotal","order_item_product_price")
val p7prod = spark.read.option("inferSchema","true").csv("/public/retail_db/products").toDF("product_id","product_category_id","product_name","product_description","product_price","product_image")

val p7jn = p7oitm.join(p7ord,'order_item_order_id === 'order_id).join(p7prod,'order_item_product_id === 'product_id)

scala> p7jn.groupBy('order_item_product_id,'product_name,'product_category_id,'order_date).agg(sum('order_item_subtotal).alias("revenue")).sort('revenue desc).limit(5).selectExpr("order_date", "revenue as order_revenue", "product_name", "product_category_id").write.mode("overwrite").option("sep",":").csv("/user/mearu0705/problem7/solution/")
warning: there was one feature warning; re-run with -feature for details
 
Results: 
scala> spark.read.option("sep",":").csv("/user/mearu0705/problem7/solution/").show
+--------------------+------------------+--------------------+---+
|                 _c0|               _c1|                 _c2|_c3|
+--------------------+------------------+--------------------+---+
|2013-07-26T00:00:...|10799.459999999995|Field & Stream Sp...| 45|
|2013-07-26T00:00:...|7978.6699999999955|Perfect Fitness P...| 17|
|2013-07-26T00:00:...| 6899.539999999997|Diamondback Women...| 43|
|2013-07-26T00:00:...| 6799.319999999998|Nike Men's Free 5...|  9|
|2013-07-26T00:00:...| 4798.080000000001|O'Brien Men's Neo...| 46|
+--------------------+------------------+--------------------+---+
